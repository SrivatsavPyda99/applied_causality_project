{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "import json\n",
    "import twitter\n",
    "import tweepy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dict()\n",
    "\n",
    "# Enter your own consumer_key, consumer_secret, access_key and access_secret\n",
    "\n",
    "info['CONSUMER_KEY'] = 'kzH6JHce26l6HhuMzHJWW8gDp'\n",
    "info['CONSUMER_SECRET'] = 'QLwzCe6lNG1JriDGvn7gxGgrngtyWrPsXliuPNIlx0TGT4X7Rb'\n",
    "info['ACCESS_KEY'] = '1094854919377637376-BL2OBuEtJCtQn6bzvEWcFiEzKn1pIf'\n",
    "info['ACCESS_SECRET'] = 'oznzrzp4yNto96xFbyhZs4WYlJIYr5mn2fGr42gISasbi'\n",
    "\n",
    "api = twitter.Api(consumer_key=info['CONSUMER_KEY'],\n",
    "                      consumer_secret=info['CONSUMER_SECRET'],\n",
    "                      access_token_key=info['ACCESS_KEY'],\n",
    "                      access_token_secret=info['ACCESS_SECRET'])\n",
    "\n",
    "auth = tweepy.OAuthHandler(info['CONSUMER_KEY'], info['CONSUMER_SECRET'])\n",
    "auth.set_access_token(info['ACCESS_KEY'], info['ACCESS_SECRET'])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "# Dictionary mapping day distance from June 04, 2010 to business day difference from June 04, 2010\n",
    "\n",
    "start_date = datetime.strptime(\"2010-07-01-+0000\", \"%Y-%m-%d-%z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: empty data matrix, csv reader object containing stock price information\n",
    "# Output: data matrix containing:\n",
    "# list of datetime objects marking 5 pm on the given day\n",
    "# 0) number of days leading into this day from previous business day\n",
    "# 1) closing stock price from previous day\n",
    "# 2) change in stock price trom t-6 to t-5\n",
    "# 3) change in stock price trom t-5 to t-4\n",
    "# 4) change in stock price trom t-4 to t-3\n",
    "# 5) change in stock price trom t-3 to t-2\n",
    "# 6) change in stock price trom t-2 to t-1\n",
    "# 8) change in stock price leading into current day\n",
    "\n",
    "def stocks_data_fill(data):\n",
    "    final_data = np.zeros((data.shape[0], 9))\n",
    "    day_list = []\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    while j < data.shape[0]:\n",
    "        current_date = datetime.strptime(data[j, 0]+\"-17:00:00-+0000\", \"%Y-%m-%d-%X-%z\")\n",
    "        #current_date = (current_date - start_date).days\n",
    "        \n",
    "        if (current_date - start_date).days >= 0:\n",
    "            day_list.append(current_date)\n",
    "            previous_date = datetime.strptime(data[j-1, 0]+\"-17:00:00-+0000\", \"%Y-%m-%d-%X-%z\")\n",
    "            final_data[i,0] = (current_date - previous_date).days\n",
    "            final_data[i,1] = data[j-1, 4]\n",
    "            final_data[i, 2] = data[j-5, 4] - data[j-6, 4]\n",
    "            final_data[i, 3] = data[j-4, 4] - data[j-5, 4]\n",
    "            final_data[i, 4] = data[j-3, 4] - data[j-4, 4]\n",
    "            final_data[i, 5] = data[j-2, 4] - data[j-3, 4]\n",
    "            final_data[i, 6] = data[j-1, 4] - data[j-2, 4]\n",
    "            final_data[i, 8] = data[j, 4] - data[j-1, 4]\n",
    "            \n",
    "            #final_data[i, 0] = int(data[j-1, 0].replace(\"-\",\"\"))\n",
    "            #final_data[i, 1] = current_date\n",
    "            #final_data[i, 2] = data[j-1, 4]\n",
    "            #final_data[i, 3] = data[j-1, 4] - data[j-2, 4]\n",
    "            #final_data[i, 6] = data[j, 4] - data[j-1, 4]\n",
    "            i = i + 1\n",
    "        j = j + 1\n",
    "        \n",
    "    return final_data, day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: list of tweet timestamps and text\n",
    "# Method: Manage rate limit by doing 100 tweets/call and implementing error handling. Auto-wait 15 mins before \n",
    "# making additional calls if rate limit has been reached\n",
    "\n",
    "def make_tweet_matrix():\n",
    "    with open('all_ids.json') as json_file:  \n",
    "        tweet_ids = json.load(json_file)\n",
    "        \n",
    "    tweet_timestamps = []\n",
    "    tweet_text = []\n",
    "    \n",
    "    i = 0\n",
    "    iter_amt = 100\n",
    "    \n",
    "    while i < len(tweet_ids):\n",
    "        try:\n",
    "            if (i + iter_amt) < len(tweet_ids):\n",
    "                tweets = tweet_ids[i:i + iter_amt]\n",
    "            else:\n",
    "                tweets = tweet_ids[i:len(tweet_ids)]\n",
    "            tweets = api.statuses_lookup(tweets)\n",
    "        except tweepy.error.TweepError:\n",
    "            print(\"out of quota, waiting 15 minutes\")\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "            \n",
    "        for tweet in tweets:\n",
    "            json_tweet = tweet._json\n",
    "            tweet_time = json_tweet['created_at']\n",
    "            tweet_date = datetime.strptime(tweet_time, \"%a %b %d %X %z %Y\")\n",
    "            \n",
    "            distance = (tweet_date - start_date).days\n",
    "            if distance < -1:\n",
    "                continue\n",
    "            #tweets[0] = (tweet_date - start_date).days\n",
    "            #tweets[1] = \n",
    "            #tweets[1] = tweet\n",
    "            tweet_timestamps.append(tweet_date)\n",
    "            tweet_text.append(json_tweet['text'])\n",
    "\n",
    "        i = i + iter_amt\n",
    "        \n",
    "    return tweet_timestamps, tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: data matrix filled in with first 3 features and the output, list containing timestamp objects for each row in data matrix,\n",
    "# lists containing tweet timestamps and contents\n",
    "# Output: data matrix containing:\n",
    "# 1) number of days leading into this day from previous business day\n",
    "# 2) closing stock price from previous day\n",
    "# 3) change in stock price leading into previous day\n",
    "# 4) Number of tweets between previous day closing time and current day closing time\n",
    "# 5) change in stock price leading into current day\n",
    "# list of datetime objects marking 5 pm on the given day\n",
    "# list containing concatonated contents of tweets between previous day closing time and current day closing time\n",
    "# Method: Iterate through twitter data and data matrix simultaneously, constructing matrix as we go\n",
    "\n",
    "def tweets_data_fill(data, day_list, tweet_times, tweet_contents):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    tweet_text = []\n",
    "    \n",
    "    while i < len(data):\n",
    "        tweets = []\n",
    "        while tweet_times[j] < day_list[i]:\n",
    "            tweets.append(tweet_contents[j])\n",
    "            data[i, 7] = data[i, 7] + 1\n",
    "            j = j + 1\n",
    "        tweet_text.append(tweets)\n",
    "        i = i + 1\n",
    "    \n",
    "    return data, day_list, tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper methods above to return the following information\n",
    "# Output: data matrix containing:\n",
    "# 1) number of days leading into this day from previous business day\n",
    "# 2) closing stock price from previous day\n",
    "# 3) change in stock price leading into previous day\n",
    "# 4) Number of tweets between previous day closing time and current day closing time\n",
    "# 5) change in stock price leading into current day\n",
    "# list of datetime objects marking 5 pm on the given day\n",
    "# list containing concatonated contents of tweets between previous day closing time and current day closing time\n",
    "\n",
    "def prep_data():\n",
    "    data_unformatted = pandas.read_csv('tesla_stock_prices.csv').as_matrix()\n",
    "    data, day_list = stocks_data_fill(data_unformatted)\n",
    "    data = data[~(data==0).all(1)]\n",
    "    \n",
    "    \n",
    "    tweet_times, tweet_contents = make_tweet_matrix()\n",
    "    my_order = [x for y, x in sorted(zip(tweet_times, range(len(tweet_times))))]\n",
    "    tweet_times = [tweet_times[i] for i in my_order]\n",
    "    tweet_contents = [tweet_contents[i] for i in my_order]\n",
    "    \n",
    "    return tweets_data_fill(data, day_list, tweet_times, tweet_contents)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data matrix to a npy file\n",
    "# Write timestamps for each row to a file\n",
    "# Write tweets to a file\n",
    "\n",
    "def write_data():\n",
    "    data, day_list, tweet_contents = prep_data()\n",
    "    day_list = [x.strftime(\"%Y-%m-%d-%X-%z\") for x in day_list]\n",
    "    \n",
    "    np_path = \"data/data.npy\"\n",
    "    day_path = \"data/dates.json\"\n",
    "    tweet_contents_path = \"data/tweets.json\"\n",
    "    \n",
    "    \n",
    "    np.save(np_path, data)\n",
    "    \n",
    "    json_day_contents = json.dumps(day_list)\n",
    "    with open(day_path, 'w') as outfile:\n",
    "        json.dump(json_day_contents, outfile)\n",
    "    \n",
    "    json_tweet_contents = json.dumps(tweet_contents)\n",
    "    with open(tweet_contents_path, 'w') as outfile:\n",
    "        json.dump(json_tweet_contents, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
